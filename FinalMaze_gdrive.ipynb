{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXJkSfKvP1Vg",
        "outputId": "464a0f7c-a554-4e51-dfd7-aee279bf8e67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4JQkQA9QgAU"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "zip_ref=zipfile.ZipFile(\"/content/drive/MyDrive/Dataset.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/Dataset\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBXJ9hup4A34"
      },
      "source": [
        "##**Importing Libraries**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "j0g5ehcF-C35"
      },
      "outputs": [],
      "source": [
        "# Provides support for large, multi-dimensional arrays and matrices, as well as a wide range of mathematical functions\n",
        "# We will be using this library to initialize our maze.\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "from scipy.sparse import dok_matrix\n",
        "# A 2D plotting library that enables users to create a wide variety of high-quality plots and visualizations.\n",
        "# We will be using this library to display our maze in a visually appealing way.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# A library that provides various functions for working with time-related operations. We will be using this library\n",
        "# to give us time to look at how the agent is progressing through the maze\n",
        "import time\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OXdlVHe-O9a"
      },
      "source": [
        "##**Creating the Maze Environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khPGglkq-R6G"
      },
      "source": [
        "The code below sets up a simple maze with walls, a starting point (S), and a goal point (G). The maze is set up on a grid where each cell is either a 0 or 1, with 0 representing a black empty space and 1 representing a white wall."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BrfkCY7w-OY3"
      },
      "outputs": [],
      "source": [
        "class Maze:\n",
        "    def __init__(self, maze, start_position, goal_position):\n",
        "        # Initialize Maze object with the provided maze, start_position, and goal position\n",
        "        self.maze = maze\n",
        "        self.maze_height = maze_layout.shape[0] # Get the height of the maze (number of rows)\n",
        "\n",
        "        self.maze_width = maze_layout.shape[1]  # Get the width of the maze (number of columns)\n",
        "        self.start_position = start_position    # Set the start position in the maze as a tuple (x, y)\n",
        "        self.goal_position = goal_position      # Set the goal position in the maze as a tuple (x, y)\n",
        "\n",
        "    def show_maze(self):\n",
        "        # Visualize the maze using Matplotlib\n",
        "        plt.figure(figsize=(5,5))\n",
        "\n",
        "        # Display the maze as an image in grayscale ('gray' colormap)\n",
        "        plt.imshow(self.maze, cmap='gray')\n",
        "\n",
        "        # Add start and goal positions as 'S' and 'G'\n",
        "        plt.text(self.start_position[0], self.start_position[1], 'S', ha='center', va='center', color='red', fontsize=20)\n",
        "        plt.text(self.goal_position[0], self.goal_position[1], 'G', ha='center', va='center', color='green', fontsize=20)\n",
        "\n",
        "        # Remove ticks and labels from the axes\n",
        "        plt.xticks([]), plt.yticks([])\n",
        "\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dx0iGuvglgXQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "from PIL import Image\n",
        "\n",
        "def generate_matrix(image_path):\n",
        "    # Load the image\n",
        "    image = Image.open(image_path)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray_image = image.convert(\"L\")\n",
        "\n",
        "    # Define the block size (20x20 pixels)\n",
        "    block_size = 20\n",
        "    num_blocks = gray_image.size[0] // block_size  # Number of blocks (21x21)\n",
        "\n",
        "    # Initialize the matrix\n",
        "    mapped_matrix = np.zeros((num_blocks, num_blocks), dtype=int)\n",
        "\n",
        "    # Process each block\n",
        "    for i in range(num_blocks):\n",
        "        for j in range(num_blocks):\n",
        "            # Get the coordinates of the block\n",
        "            block = gray_image.crop((j * block_size, i * block_size, (j + 1) * block_size, (i + 1) * block_size))\n",
        "\n",
        "            # Calculate the average color in the block\n",
        "            avg_color = np.mean(block)\n",
        "\n",
        "            # If the average color is closer to white (255), mark the block as 1, else 0\n",
        "            mapped_matrix[i, j] = 1 if avg_color > 128 else 0\n",
        "\n",
        "    return mapped_matrix\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "fXssFI9q_gic",
        "outputId": "32e3ceca-3f91-407d-b8d2-f508e749b585"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "maze_layout=generate_matrix(\"E:/Major_project/Major Project/Major Project/Final_model/archive/rectangular_mazes/7.png\")\n",
        "# Create an instance of the maze and set the starting and ending positions\n",
        "maze = Maze(maze_layout, (0, 1), (20, 19))\n",
        "# Visualize the maze\n",
        "# print(maze_layout[0,1])\n",
        "maze.show_maze()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59R0EpWI_mQt"
      },
      "source": [
        "##**Implementing the Agent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNX8sLyO_pIB"
      },
      "source": [
        "The code below is for the agent. The agent can move in four directions: up, down, left, and right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "rPZ-3Uh3_oJN"
      },
      "outputs": [],
      "source": [
        "# Actions the agent can take: Up, Down, Left, Right. Each action is represented as a tuple of two values: (row_change, column_change)\n",
        "actions = [(-1, 0), # Up: Moving one step up, reducing the row index by 1\n",
        "          (1, 0),   # Down: Moving on step down, increasing the row index by 1\n",
        "          (0, -1),  # Left: Moving one step to the left, reducing the column index by 1\n",
        "          (0, 1)]   # Right: Moving one step to the right, increasing the column index by 1\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, maze, learning_rate=0.1, discount_factor=0.9, exploration_start=1.0, exploration_end=0.01, num_episodes=100):\n",
        "        # Initialize the Q-learning agent with a Q-table containing all zeros\n",
        "        # where the rows represent states, columns represent actions, and the third dimension is for each action (Up, Down, Left, Right)\n",
        "        self.q_table = np.zeros((maze.maze_height, maze.maze_width, 4)) # 4 actions: Up, Down, Left, Right\n",
        "        self.learning_rate = learning_rate          # Learning rate controls how much the agent updates its Q-values after each action\n",
        "        self.discount_factor = discount_factor      # Discount factor determines the importance of future rewards in the agent's decisions\n",
        "        self.exploration_start = exploration_start  # Exploration rate determines the likelihood of the agent taking a random action\n",
        "        self.exploration_end = exploration_end\n",
        "        self.num_episodes = num_episodes\n",
        "\n",
        "    def save_model(self, file_path='q_table.pkl'):\n",
        "        with open(file_path, 'wb') as file:\n",
        "            pickle.dump(self.q_table, file)\n",
        "        # print(f\"Q-table saved to {file_path}\")\n",
        "\n",
        "    # Method to load the model (Q-table)\n",
        "    def load_model(self, file_path='q_table.pkl'):\n",
        "        with open(file_path, 'rb') as file:\n",
        "            self.q_table = pickle.load(file)\n",
        "        # print(f\"Q-table loaded from {file_path}\")\n",
        "\n",
        "    def get_exploration_rate(self, current_episode):\n",
        "        # Calculate the current exploration rate using the given formula\n",
        "        exploration_rate = self.exploration_start * (self.exploration_end / self.exploration_start) ** (current_episode / self.num_episodes)\n",
        "        return exploration_rate\n",
        "\n",
        "    def get_action(self, state, current_episode): # State is tuple representing where agent is in maze (x, y)\n",
        "        exploration_rate = self.get_exploration_rate(current_episode)\n",
        "        # Select an action for the given state either randomly (exploration) or using the Q-table (exploitation)\n",
        "        if np.random.rand() < exploration_rate:\n",
        "            return np.random.randint(4) # Choose a random action (index 0 to 3, representing Up, Down, Left, Right)\n",
        "        else:\n",
        "            return np.argmax(self.q_table[state]) # Choose the action with the highest Q-value for the given state\n",
        "\n",
        "    def update_q_table(self, state, action, next_state, reward):\n",
        "        # Find the best next action by selecting the action that maximizes the Q-value for the next state\n",
        "        best_next_action = np.argmax(self.q_table[next_state])\n",
        "\n",
        "        # Get the current Q-value for the current state and action\n",
        "        current_q_value = self.q_table[state][action]\n",
        "\n",
        "        # Q-value update using Q-learning formula\n",
        "        new_q_value = current_q_value + self.learning_rate * (reward + self.discount_factor * self.q_table[next_state][best_next_action] - current_q_value)\n",
        "\n",
        "        # Update the Q-table with the new Q-value for the current state and action\n",
        "        self.q_table[state][action] = new_q_value\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FbuYR2CAn1_"
      },
      "source": [
        "##**Defining the Reward System**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJcGuXGGAr9i"
      },
      "source": [
        "This code determines the values for the reward system. The reward system provides feedback to the agent in reinforcement learning.\n",
        "\n",
        "Use these default settings to see how the agent performs when untrained, and when initially trained."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImjtvwVSAwTa",
        "outputId": "57a967b9-0cd7-4a53-f83e-12934813e675"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The reward system has been defined.\n"
          ]
        }
      ],
      "source": [
        "goal_reward = 100\n",
        "wall_penalty = -10\n",
        "step_penalty = -1\n",
        "\n",
        "print(\"The reward system has been defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5_ZzP1ZBB_D"
      },
      "source": [
        "## **Testing the Agent**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lnZqfOpMo22Z"
      },
      "source": [
        "The code below tests how well the agent navigates the maze. It reports the total number of steps the agent took to get through the maze as well as the total reward the agent accumulated.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "uaHLrAd0ov3Q"
      },
      "outputs": [],
      "source": [
        "# This function simulates the agent's movements in the maze for a single episode.\n",
        "\n",
        "def finish_episode(agent, maze, current_episode, train=True):\n",
        "    # Initialize the agent's current state to the maze's start position\n",
        "    current_state = maze.start_position\n",
        "    is_done = False\n",
        "    episode_reward = 0\n",
        "    episode_step = 0\n",
        "    path = [current_state]\n",
        "\n",
        "    # Continue until the episode is done\n",
        "    while not is_done:\n",
        "        # Get the agent's action for the current state using its Q-table\n",
        "        action = agent.get_action(current_state, current_episode)\n",
        "\n",
        "        # Compute the next state based on the chosen action\n",
        "        next_state = (current_state[0] + actions[action][0], current_state[1] + actions[action][1])\n",
        "\n",
        "        # Check if the next state is out of bounds or hitting a wall\n",
        "        if next_state[0] < 1 or next_state[0] >= maze.maze_height or next_state[1] < 1 or next_state[1] >= maze.maze_width or maze.maze[next_state[1]][next_state[0]] == 0:\n",
        "            reward = wall_penalty\n",
        "            next_state = current_state\n",
        "        # Check if the agent reached the goal:\n",
        "        elif next_state == (maze.goal_position):\n",
        "            path.append(current_state)\n",
        "            reward = goal_reward\n",
        "            is_done = True\n",
        "        # The agent takes a step but hasn't reached the goal yet\n",
        "        else:\n",
        "            path.append(current_state)\n",
        "            reward = step_penalty\n",
        "\n",
        "        # Update the cumulative reward and step count for the episode\n",
        "        episode_reward += reward\n",
        "        episode_step += 1\n",
        "\n",
        "        # Update the agent's Q-table if training is enabled\n",
        "        if train == True:\n",
        "            agent.update_q_table(current_state, action, next_state, reward)\n",
        "\n",
        "        # Move to the next state for the next iteration\n",
        "        current_state = next_state\n",
        "\n",
        "    # Return the cumulative episode reward, total number of steps, and the agent's path during the simulation\n",
        "    return episode_reward, episode_step, path\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihUJlT3HNwgZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGFiGxS9OORv"
      },
      "source": [
        "##**Setting Up the Reinforcement Learning Loop**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3Pw8SjLORia"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdCGxQmOOfph",
        "outputId": "98a08305-0451-4dab-a5d9-88d7883e8407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "This code block has been run and the train_agent function is now available for use.\n"
          ]
        }
      ],
      "source": [
        "def train_agent(agent, maze, num_episodes=100):\n",
        "    # Lists to store the data for plotting\n",
        "    episode_rewards = []\n",
        "    episode_steps = []\n",
        "\n",
        "    # Loop over the specified number of episodes\n",
        "    for episode in range(num_episodes):\n",
        "        episode_reward, episode_step, path = finish_episode(agent, maze, episode, train=True)\n",
        "\n",
        "        # Store the episode's cumulative reward and the number of steps taken in their respective lists\n",
        "        episode_rewards.append(episode_reward)\n",
        "        episode_steps.append(episode_step)\n",
        "\n",
        "    # Plotting the data after training is completed\n",
        "    plt.figure(figsize=(10, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(episode_rewards)\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Cumulative Reward')\n",
        "    plt.title('Reward per Episode')\n",
        "\n",
        "    average_reward = sum(episode_rewards) / len(episode_rewards)\n",
        "    print(f\"The average reward is: {average_reward}\")\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(episode_steps)\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Steps Taken')\n",
        "    plt.ylim(0, 100)\n",
        "    plt.title('Steps per Episode')\n",
        "\n",
        "    average_steps = sum(episode_steps) / len(episode_steps)\n",
        "    print(f\"The average steps is: {average_steps}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "print(\"This code block has been run and the train_agent function is now available for use.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_on_multiple_mazes(agent, mazes, num_episodes=100):\n",
        "    for maze in mazes:\n",
        "        # Train the agent on each maze for a few episodes\n",
        "        for episode in range(num_episodes):\n",
        "            episode_reward, episode_step, path = finish_episode(agent, maze, episode, train=True)\n",
        "            # Optional: Save progress after certain intervals\n",
        "            if episode % 1000 == 0:\n",
        "                agent.save_model(f'q_table_{episode}.pkl')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "k0iqqGUaAyto"
      },
      "outputs": [],
      "source": [
        "# This function evaluates an agent's performance in the maze. The function simulates the agent's movements in the maze,\n",
        "# updating its state, accumulating the rewards, and determining the end of the episode when the agent reaches the goal position.\n",
        "# The agent's learned path is then printed along with the total number of steps taken and the total reward obtained during the\n",
        "# simulation. The function also visualizes the maze with the agent's path marked in blue for better visualization of the\n",
        "# agent's trajectory.\n",
        "\n",
        "def test_agent(agent, maze, num_episodes=1):\n",
        "    # Simulate the agent's behavior in the maze for the specified number of episodes\n",
        "    episode_reward, episode_step, path = finish_episode(agent, maze, num_episodes, train=False)\n",
        "    \n",
        "    fpath=[]\n",
        "    for row, col in path:\n",
        "        # print(f\"({row}, {col})-> \", end='')\n",
        "        if(fpath.__contains__((row,col))):\n",
        "            print()\n",
        "        else:\n",
        "            fpath.append((row,col))\n",
        "        \n",
        "\n",
        "    print(\"Number of steps:\", episode_step)\n",
        "    print(\"Total reward:\", episode_reward)\n",
        "\n",
        "    # Clear the existing plot if any\n",
        "    if plt.gcf().get_axes():\n",
        "        plt.cla()\n",
        "\n",
        "    # Visualize the maze using matplotlib\n",
        "    plt.figure(figsize=(5,5))\n",
        "    plt.imshow(maze.maze, cmap='gray')\n",
        "\n",
        "    # Mark the start position (red 'S') and goal position (green 'G') in the maze\n",
        "    plt.text(maze.start_position[0], maze.start_position[1], 'S', ha='center', va='center', color='red', fontsize=20)\n",
        "    plt.text(maze.goal_position[0], maze.goal_position[1], 'G', ha='center', va='center', color='green', fontsize=20)\n",
        "\n",
        "    # Mark the agent's path with blue '#' symbols\n",
        "    for position in path:\n",
        "        plt.text(position[0], position[1], \"*\", va='center', color='blue', fontsize=20)\n",
        "\n",
        "    # Remove axis ticks and grid lines for a cleaner visualization\n",
        "    plt.xticks([]), plt.yticks([])\n",
        "    plt.grid(color='black', linewidth=2)\n",
        "    plt.show()\n",
        "\n",
        "    return fpath\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jrZKOEZOiKH"
      },
      "source": [
        "##**Training the Agent**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "jHry-2UIP0iW",
        "outputId": "1005db5b-a885-4537-e9f2-f3040e100ed2"
      },
      "outputs": [],
      "source": [
        "# Training the agent\n",
        "agent = QLearningAgent(maze)\n",
        "\n",
        "train_agent(agent, maze, num_episodes=90000)\n",
        "agent.save_model('q_table1.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "0t9kcynWO1Hw",
        "outputId": "3e6e6515-4e69-4d44-c46d-437feff73ab3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Number of steps: 42\n",
            "Total reward: 59\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAGVCAYAAADdbNc4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAfqElEQVR4nO3df4xV533n8fcMP2qoGVKT+Ac1YSLXP2AZj5bEcR35x2BLmUBJ3VUjJa5CDGiroF1VtQmYNsoPvK22NqSp1cZrRwqG1N00ThUlEYxKtLHNNqkSx5UdDAxt0xY2rifgJLVngMF2YJ7943g8EN+Ze2bmufc859z3SzrSDPfy3Oec88x85vx4zrcthBCQJCmS9qI7IEmqFoNFkhSVwSJJispgkSRFZbBIkqIyWCRJURkskqSoDBZJUlQz87xpZGSEgYEB5s2bR1tbW6P7JElKSAiBEydOsHDhQtrb6x+P5AqWgYEBFi1aNO3OSZLK6/nnn+fyyy+v+75cp8LmzZs37Q5JksotbxbkChZPf0mS8maBF+8lSVEZLJKkqAwWSVJUBoskKSqDRZIUlcEiSYrKYJEkRWWwSJKiMlgkSVEZLJKkqAwWSVJUBoskKappBctc4KNAH/DvwGngFeBF4PvADuC/AtlDln8O/HA6H/e6I8DOCO1IkhohVz2WWn4d+DKwuMZrb3t9uQ5YDxwDLpvqB0mSSmVKRyxXAt9kLFS+AawBrgf+M3AFH2cdV/JN4LUJW/ovwAcmeL0XWJCjR8uAa3O8T5LUcCGHwcHBAITBwcHsHz7wgRAgW3buPO+9zz+f/XNbWwjr1oVw9tiLIXzuc2HGjBCuuCJ7z09+EsK735297y1vGe8zQ+joCGHBghAeeSSEkZHs3xcvDuHOO7OvT50K4Z57Qpg5M4Senjxr0lhAtEWSYoj5e+mNDKhj8kcsZ89CX1/29bveBWvXnvfy5ZfDF78IHR2wcydcdPXb2LP4v7/x+tatcOml8P3vw5VXwpNP1v6Yjg54/HFYtgzWr4eeHjh8eOz1vj5YuhQ+8xn4yEfgS1+a9JpIkhqg7fVEm9DQ0BDz589ncHCQjuFhuOz1KyYf+hD89V+P+/8+/nH40z+F137hfNiCBfD5z8Nv/3a+Tn7jG7BlCxw5kn0/ezacPAm9vbB9O3R15Wun0WJW2syxWySprpi/lwYHB+no6Kj/mZMOljNnsmQA6O6GH/xgwv/78suweDEMDWXfX3dddrQyWa+8Au99L3z729n3mzfDtm2Tb6eRDBZJqSkiWCZ/Kuyii7KkANi/H+6/H0ZGar71U5+CSy4ZCxWAp5+Giy/OjkLy2rMHli+Hp57KjlYuvDA7Ulm1Cg4dmvQaSJIaaGrzWH7v98a+/oM/gCuugN//fXjsMThyhMcey/Lnj/4I5syB3bthxozsbZ/8JPzHf8Bv/VZ2jeTgwfE/5gc/gNtug/e/H972tuz7yy7LTqHt3g39/dlB04YNcPz4lNZEkhRbniv8b7or7OzZENavH7sz7JzlBS4NMBLaOBvW3vb/wtkz2e1cv3hX2HXXTXxX2NDQ2F1hO3aMf1fY5s3ZXWErVuS6WaGh8K4wSYmJ+Xsp711hU5sg2d4OO3ZkF+8/+1n41rfgzBkAFnKMe/kUH+Qxrn78h/Dr74Ivfxm44o3//ta3ZtdZvvrV7CazWubNy/7bdddl769l7tzsOsuaNeOejZMkNdnkL97XunAzNAR///fZBZR/+Af4u7+DwcGx1y+7jJkvvkBnZxv/8i/T63BnZ3br8a5d02unEbx4Lyk1RVy8n/IjXc7T0QErV2YLwKuvZhNLPvYxeOkl+PGPoW0EmBHl4yRJ6YoTLL/ol34J1q2DhQvhfe8D4Mxb3gb//FOm+0Dlo0en3z1JUuM09rH5vb2waFH29Usvwc9+1tCPkyQVr/H1WBYuHPs64rk+SVKaGhssw8PZZBPIrsMsyPOkYklSmU0+WE6ehOuvz6bDT3SP78hINpHyxIns+9/8TY9YJKkFTP524/b2bJIJwK/+ajaF/oYbsse8zJuXPRzs2WfhkUfgwIHsffPnZ9PmOzun3WFvN5ak/Mpxu/HMmdlz748dgxdegAcfzJbxXHll9gTkCKEiSUrf5IPlgguyQPne97IZ99/7HvzTP2UP63rlFfjlX84u2Hd3w+23Zw/2mj17Sp3buzcr+TLezPtRBw5kZ966u6f0MZKkiKb+SJf3vCdbGmRoCD74QZg1K3uS8dq1b75EMzwM996bPVXmxhvHLxomSWqiPA8UG30IZYxlMp5+OoRbbskeVnnzzSH09489hHLPnhDgSIAzAb4Q4NKoD1tzadxDMVPrU9HbttUW91t5l7wPoZzUxfsYcnzcm4xXQRL2ApuBCZ69ryimst/GE+tiYqw+xby4qfrcb+XVuEJfBbj99uymsuuvz8ocnzyZVZCElRgqkpSWUgTLeBUkoQ9YWnDvJEnnSjpY6lWQzEJlP/AQcHGBPZUkjWrM040jOHECbrkluytsx47sYcnnnlJdvRqyYNkK3A1cBdxWQE8lSedKNljyVJCE08AW4FESP/iSpJaRbLDAWN2w+ryAL0mp8M98SVJUSR+x1GIFSUlKm0cskqSoDBZJUlQGiyQpKoNFkhRV6YKlszN7hL4kKU2lCxZJUtqSDpa9e+GnP83zzmXAtQ3ujSQpj2SDZbSC5DXXwM6dULuEwxzgPuAZ4IFmdk+SNI5kJ0h2dMDjj8OmTbB+PezaBQ8/PPZ6Xx8sXjzM889n11z++I9XcNll8YpRVYXFkJorZkE0NU+V91sRvwNKXUGytzery9LVFaVrlZRatUZIr08xf/Cq/AsqNe63fGJup5aoILl3r6EiSakpRbCMV0Fy1So4dKjo3kmSzpV0sNSrINnfD93dsGEDHD9edG8lSZBwsIxWkNy/P6sguW8fLFky9vrq1VmwbNyYvX7HHYV1VZJ0jmTvCstTQXLuXNi2DdasgZGR5vZPklRbssEC+StIegFfktKR7KkwSVI5JX3EUosVJCUpbR6xSJKiMlgkSVEZLJKkqAwWSVJUpQsWK0hKUtpKFyySpLQlHSx5K0geOJA9+kWSVLxkgyVPBcnh4axOy/LlcNddTe+iJKmGZCdI5qkguXr1UWARsIt9+z5BW9uxYjrbAqxEmU9q2ynFAm0pSm3dyl54rNQVJGEvsBk4GKVvKpcUK0imxmApp1T3W0tUkISVGCqSlJZSBMt4FSShD1hacO8kSedKOljqVZDMQmU/8BBwcYE9lSSNSvbi/WgFyVmzsgqR69bBuacKV6+GLFi2AncDVwG3FdBTSdK5kg2WPBUk4TSwBXiUxA++JKllJBsskL+CpBfwJSkd/pkvSYoq6SOWWqwgKUlp84hFkhSVwSJJispgkSRFZbBIkqIyWCRJUZUuWOKWJj4C7KxgO7HbkqT8ShcskqS0JR0seUsTwzLg2jrv6QUWRGgrtXZityVJ05NssOQpTQxzgPuAZ4AHJmhtHvAY8I/A2nHek6et1NqJ3ZYkRRByGBwcDECUZTKefjqEW24JAUK4+eYQ+vtDWLw4hDvvDGHPnuzr9vYQ1q8PYWCgOW2l1k69tmBVgCMBzgT4QoBLG77fNH1F/LyVsU+pSXEbxeoTEAYHB/N9Zp43FRUso77+9RCuvjqE2bOz5cILs1+ivb0hPPdcMW2l1s5EbcHfBliWzEBXfVX+BVVlKW4jg2UCp0+HcNNNo78oQ9i8ecpNRWsrtXZqtQX3JzfQVV/RP29l6VNqUtxGBss4du8OYcmSN/8lvnJlCAcPFtNWau1M1Bb0BViazEBXfVX+BVVlKW6jIoIl2Yv3UL80cX8/dHfDhg1w/Hhz2kqtnXptwWos4SypqfKkTxFHLENDIXR0hLBgQQg7doQwMpL9++hF6RBCOHUqO200c2YIK1Y0vq3U2snTVrbd54TslNhrAR4v/C8o1dfsn7ey9ik1KW6jWH1iEkcsydZjyVOaeO5c2LYN1qyBkZHGt5VaO3nbsoSzpGZKNlggf2nirq7mtZVaO5NpyxLOkprBP18lSVG1vX4ObkJDQ0PMnz8/ygfm+DhF1NbWFqUd91tzpbjfUuxTalLcRrH6BDA4OEhHR0fd93nEIkmKymCRJEVlsEiSojJYJElRJX27saausxN6eoruhaRW5BGLJCkqg6UC4lbalKTpMVhKLm6lTUmavqZfY4k5WafK8k6Q6uiAxx+HTZtg/XrYtQsefvjcd6wCHgQWAbuAT0ypPynut1iTyFJct1hSXLcU+1TlSZtFaPrMe+UzlYH+jW/Ali1w5Ej2/ezZcPIkwF5gM1V7VpjBolhSG0vOvFcybr89q8Vy/fXw2mujobINWEnVQkVSugyWCtmzB5Yvh6eeyo5WLrwQ4B6gj6zYlyQ1nsFSAVaQlJQSJ0iW3IkTcMstMGsW7NgB69bB+adU+4AngK3A3cBVwG3N76iklmGwlJwVJCWlxmCpACtISkqJf75KkqJyHkuiUruvPkVuI8WS2lhyHoskSecwWCRJURkskqSoDBZJUlQGiyQpKuexVJSliSUVxSMWSVJUBksFWJpYUkqafiosxYk/qU2OmozR0sSzZsH27bB27S8+hBKy0sSfBjYC3wFunfTnpLjfYkmxemBqY1v5uL0zHrGU3Ghp4mXLstLEPT1w+PC571gF9AObgL8EfqeAXkpqJU1/pEuKf/mmeMSSWmniKu+3FLmNFIuPdNG0WJpYUgoMlgqxNLGkFBgsFWBpYkkpcYJkyVmaWFJqDJaSszSxpNQYLBVgaWJJKfHPV0lSVM5joTrzWGpJbRtBmn1KjdtIsTiPRZJUegaLJCkqg0WSFJXBIkmKytuNK8oKkpKK4hGLJCkqg6UCrCApKSUGS8mNVpC85hrYuRNqT1uYA9wHPAM80MzuSWpBXmMpudEKkps2ZRUkd+2Chx8+9x2rgAeBRcAu4BPN72SDpFbiGKo9ITHF7R1LahOSy86Z96Q5qKwgWU6pjSX3Wz6p7bdUOfO+BVlBUlIKDJYKsYKkpBQYLBVgBUlJKfHifclZQVJSagyWkrOCpKTUGCwVYAVJSSnxz1dJUlTOYyHNe9hT61OK+y1F7rdySm2/pcp5LJKkQhgskqSoDBZJUlQGiyQpKm83rigrSEoqikcskqSoDJYKsIKkpJQYLCVnBUlJqSn1NZYqV+vLq4wVJN1v5ZTafktxMmJq2wiK2U6lnnmfmqJn3pelgqTqS3HmfWqK/nkri5jbyZn3LcgKkpJSYLBUiBUkJaXAYKkAK0hKSkmpL97LCpKS0mOwlJwVJCWlxmCpACtISkqJf75KkqJyHktEKd5X73yIcnK/1Zfiz1uKnMciSSo9g0WSFJXBIkmKymCRJEXl7cYVZQVJSUXxiEWSFJXBUgFWkJSUEoOl5KwgKSk1pb7G4iSyclaQTLHyX1WluK1T/HlLcTuVWaln3qcWLEXPBC5LBUl/iFtbij9vyseZ9y3ICpKSUmCwVIgVJCWlwGCpACtISkpJqS/eywqSktJjsJScFSQlpcZgqQArSEpKiX++SpKich4Lad5Xn1qfUtxvKqfUxrbycx6LJKkQBoskKSqDRZIUlcEiSYrKYJEkReU8loqyNLGkonjEIkmKymCpAEsTS0qJwVJyliaWlBqDpeRGSxMvW5aVJu7pgcOHx17fsyewePEw7e1bWL9+FgMDKwghTHpJ0VTWoyxLlbdRldctxaUIPtKFNB8xMZU+jVeauLcXtm+Hrq5o3ZuW1PZbitxGiiXm7yUf6dKCapUm3rw5uwaTSqhIqj6DpUJqlSbevh1WrYJDh4runaRWYbBUwESliXfvhv5+6O6GDRvg+PGieyup6gyWkhstTbx/f1aaeN8+WLJk7PXVq7Ng2bgxe/2OOwrrqqQW4cz7kstTmnjuXNi2DdasgZGR5vZPUusxWCogb2liL+BLagZPhUmSovKIpaKOHi26B5JalUcskqSoDBZJUlQGiyQpKoNFkhSVwVJRnZ2wdm3RvZDUigwWSVJUBksF5K0geeBA9ugXSWokg6Xk8lSQHB7O6rQsXw533dX0LkpqMU2fIBmz6IzGKkhu2pRVkNy1Cx5+eOz1trbfAB4EFgG72LfvE7S1HSums5GlOJaqXFgrteJjKe5/ZZpeQTJFKQ70mBUkYS+wGTgYrX+qLbWxZMVWxWQFyRZUq4IkbANWYqhIahaDpUJqVZCEe4A+YGmxnZPUMgyWCpiogiSsJguV/cBDwMXFdVRSS/DpxiU3WkFy1qysQuS6dXD+qec+4AlgK3A3cBVwW/M7KqllGCwll6eCJJwGtgCP4kGqpEYzWCogbwVJL+BLagb/fJUkReU8FtK8rz7FPqm+1Pab81gUk/NYJEmFMFgkSVEZLJKkqAwWSVJUBoskKSrnsVRUZyf09BTdC0mtyCMWSVJUBksF5C1NDMuAaxvcG0mtrumnwqpcYa+IdRstTTxrFmzfDmvXnv8QyhACw8Nw773w2c/CjTfCk082vZtJc6JdOVX5d0lMRYxvj1hKbrQ08bJlWWninh44fHjs9b4+WLoUPvMZ+MhH4EtfKqyrklpE0x/p4l8ZjTNeaeLe3uxopqur2P6lqsqP4qnyI12UT8zx7SNdWlCt0sSbN2fXYAwVSc1isFRIrdLE27fDqlVw6FDRvZPUKgyWCpioNPHu3dDfD93dsGEDHD9edG8lVZ3BUnKjpYn3789KE+/bB0uWjL2+enUWLBs3Zq/fcUdhXZXUIpx5X3J5ShPPnQvbtsGaNTAy0tz+SWo9BksF5C1N7AV8Sc3gqTBJUlQesVTU0aNF90BSq/KIRZIUlcEiSYrKYJEkRWWwSJKiMlgqqrMze4S+JDWbwSJJispgqYC8FSQPHMge/SJJjWSwlNxoBclrroGdO6FWqYvh4axOy/LlcNddTe+ipBZT6gmSVS4pm7cY0mgFyU2bsgqSu3bBww+Pvd7W9hvAg8AiYBf79n2CtrZjDeixUlTln5Eqr1vZi6GVuoKkA+t841WQhL3AZuBgxB6qltQqSKbIbVRfqr8nrSDZgmpVkIRtwEoMFUnNYrBUSK0KknAP0AcsLbZzklqGwVIBE1WQhNVkobIfeAi4uLiOSmoJpb54r7EKkrNmZRUi162D80+p9gFPAFuBu4GrgNua31FJLcNgKbk8FSThNLAFeBQPUiU1msFSAXkrSHoBX1Iz+OerJCkq57Ekynv9y8n9Vp/bqL5Uf086j0WSVAiDRZIUlcEiSYrKYJEkReXtxhXV2Qk9PUX3QlIr8ohFkhSVwVIBeStIwjLg2gb3RlKrM1hKLk8FSZgD3Ac8AzzQzO5JakEGC9lkpNSWvEYrSC5bllWQ7OmBw4fHXt+zJ7B48TDt7VtYv34WAwMrCl+3Ki+pKXp7lGEbQXrbqeyceU/5y4COGq+CZG8vbN8OXV3F9k/5Obbrizmj3O2UjzPvW1CtCpKbN2fXYAwVSc1isFRIrQqS27fDqlVw6FDRvZPUKgyWCpioguTu3dDfD93dsGEDHD9edG8lVZ3BUnKjFST3788qSO7bB0uWjL2+enUWLBs3Zq/fcUdhXZXUIpx5X3J5KkjOnQvbtsGaNTAy0tz+SWo9BksF5K0g6QV8Sc3gqTBJUlQesVTU0aNF90BSq/KIRZIUlcEiSYrKYJEkRWWwSJKiMlgqqrMT1q4tuheSWpHBIkmKymCpgLwVJA8cyB79IkmNZLCUXJ4KksPDWZ2W5cvhrrua3kVJrSbkMDg4GACXJi6T8fTTIdxySwgQws03h9DfH8LixSHceWcIsCrAkQBnAnwhwKWFr5tLay+xFL0erbgMDg7m2jdNryCpfHLsljcZr4Ik7AU2Awcj9lCamqmM7VpiVkZUPlaQbEG1KkjCNmAlhoqkZjFYKqRWBUm4B+gDlhbbOUktw2CpgIkqSMJqslDZDzwEXFxcRyW1BJ9uXHKjFSRnzcoqRK5bB+efeu4DngC2AncDVwG3Nb+jklqGwVJyeSpIwmlgC/AoHqRKajSDpQLyVpD0Ar6kZvDPV0lSVM5jSZT3+quqHNvl5TwWSVIhDBZJUlQGiyQpKoNFkhSVwSJJisp5LBXV2Qk9PUX3QuV3BNgHrIvY1vQ4ttPnEYskKSqDpQLyliaGZcC1De6NyqsXWJDjfXnGUb626pXLdmyXk8FScnlKE8Mc4D7gGeCBZnZPpTEPeAz4R2DtOO/JO47qt5WnXLZju8TylJmMWZpY8TWjNHFMjqX6ithGE42jPXuyr9vbQ1i/PoSBgea01ayy21UWaywxidLEBkuFfP3rIVx9dQizZ2fLhRdmP5DwtwGWJbPfHEv1FbmNxhtHvb0hPPdcMW01cmw7lgwW1XH6dAg33TT6QxcC3J/cfnMs1Vf0NvrFcbR589TXJVZbjRrbjqX4weI1lgqxNLFiqDWOtm+HVavg0KFi2nJsl4vBUgGWJlYME42j3buhvx+6u2HDBjh+vDltObZLKs9hjafC0jU0FEJHRwgLFoSwY0cIIyPZv49d4CTAnNdPG7wW4PHC95tjqb5mb6N64yiEEE6dyk5jzZwZwooVjW+rWWPbsRT/VJgz70vO0sSKIc84mjsXtm2DNWtgZKTxbTm2y8tgqQBLEyuGvOOoq6t5bTm2y8mIlyRF1fTSxDk+ThHFKt8ac7+l2KfUuI3qi1ma2O2Uj6WJJUmFMFgkSVEZLJKkqAwWSVJUBktFdXbC2rVF90Jll+I4SrFPOp/BIkmKymCpAKvsKYa846he1ceYHNvlZLCUnFX2FEOecZSn6mOz++TYTlSeB4rFfAhlikssRfWpVStIprikto0mo17VxyKqNTargmRqS0wx+5Vsoa8Ul1iK7lOrVZBMcUltG01FitUaG92n1JaYYvbLYClgJ6bQp1aqIJnikto2mqpaVR9T61PMCpKpLTHF7JcVJFuQVfYUw3hVH4scR47tcjFYKsAqe4qhXtXHIsaRY7uk8hzWeCosnyL61MoVJFNcUttGeeWp+tjsao3NrCCZ2hJTzH5ZQbJFWGVPMaQ4jlLsk/IxWCrAKnuKIcVxlGKfVJ8RL0mKqukVJFOUYxPkkmJFuxQrEcbcTqlxv9WX2jZKUYr7DawgKUkqiMEiSYrKYJEkRWWwSJKiMlgkSVE5j6WiOjuhpydGS0eAfdNuZbQ/u3ZNuynG+rSuYu1Ufb/FEX8bTX+/xR9L01N3v7UDVwO/BlwOXAhcAPwcGAaOA88D/cDLk/98g0WSWsnVwHuBBTVem0EWMBcBS15/3z8D3wJezP8RngqrgHjlW3upPdrOV680bdxysvn6FGvdmrWNoOr7LY5mb6MUx2TU/bb8WvjQOR97BPgm8JfA54FHgK8ATwEvvf6eq4B352n/HHkeKBbzIZRVFmsbTWY7DQ6OPajvkUdqPzzw1KkQ7rknhJkzQ+jpKUc7Kfap1dcte+DjfSF74OMTLTe2U+zTZNqZMfNsoPOJwFbCJdsvCU8eeXL8FQ0hnDl7JvzV/r8Kb/+zt4d1X103qYdQGiwRFREsIdQvKbt4cQjt7SGsXx/CwEB52kmxT628bqmVJna/TaadkTBj+c7Axy4NHX/SEX74sx9OvJLneOn0S+HLz3zZYClKUcEyarzyrb29ITz3XHnbSbFPrbhuKZYmdr/la+fD/+v+wFYCWwl/8dRfTG5Fw1gGGCwFKDpYQqhdUrYK7aTYp1ZbN8d2+n2q1c7IyEhYcP+CwFbCvP85L5x89eSk2zVYClR0sOzeHcKSJW/+i2XlyhAOHixvOyn2qRXXDfoCLHVsJ9qn8dq58dahwH9bGthKWPW/V01uJV9nsBSoqGB59tkQbr219jnW3buzr2fMCOGjHw3h2LHytJNin1p53bJrLD8P8FCAi1tybKfYp3rtvHXhiUDbzwPvfCjc9Td/MvHKjcNgKVARwZKnpOypU9kh8cyZIaxYUY52UuxTq69baqWJm72NUuxTnna2Pfm5wHvuD7S/Fq5854/GXbezI2fDgeMHai7f/dfvBtotTdwy8pRvnTsXtm2DNWtgZKQc7aTYp1ZftxRLE7vf6rfzavtL8N5PQvej/M7N/wNYVPN9Q68O0fVQV+1GAOqXYXmDwVIBecu3dk0wZlJsJ2ZbqbUTs61mt5NiaWL32/jmzZ6XfXHJQS56x/P5PnSaDBZJqrAFc8dm9//k1E/Gfd9bLngL4dPhvH9b+/W1fHH/Fyf9mQZLRR09Ws12YraVWjsx20qtnZhSXLfU+nRuO92XdL/x9bPHno3zAXX4rDBJqrBlFy9jwZzsqOXbP/o2wz8fbvhnGiySVGFtbW18+NoPA9kF+i/+YPKntibLYJGkitt4w0YumHkBAH/4+B9y5KUjDf08g0WSKu7t89/On7/vzwEYfHWQG3feyHd+9J0J/08IgZdfeXlKn+fFe0lqAb/7zt/lhRMvcO//vZeBEwPctPMmbn3Hrbz/qvfTdXEXF825iLPhLMdOHuOZHz/DVw59hUM/OQTAjLYZnD17NvdntYUQQr03DQ0NMX/+/Kmv0TlyfFxptbW1RWuryttJ5RRrfDu2i/W1w19j0//ZxL+99G9139tGG72/1sunb/g0N1xxA4ODg3R01J8pabBEZLCoygyW6jgzcoavHf4a3/zXb/Ldf/8uL556kZdfeZm5s+ayYM4Cui7p4obLb+CD/+mDvONX3vFGBhgsBTBYVGUGS+uabLA0/RpLzF++VeZ2UlU5tqvPu8IkSVEZLJKkqAwWSVJUBoskKSqDRZIUlcEiSYrKYJEkRWWwSJKiMlgkSVEZLJKkqAwWSVJUBoskKSqDRZIUlcEiSYrKYJEkRWWwSJKiyhUsVnyTJOXNglzBcuLEiWl1RpJUfnmzIFfN+5GREQYGBpg3b55lRSWpxYQQOHHiBAsXLqS9vf7xSK5gkSQpLy/eS5KiMlgkSVEZLJKkqAwWSVJUBoskKSqDRZIUlcEiSYrq/wMApjSIDmPohQAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(0, 1), (1, 1), (1, 2), (1, 3), (1, 4), (1, 5), (2, 5), (3, 5), (4, 5), (5, 5), (5, 6), (5, 7), (5, 8), (5, 9), (5, 10), (5, 11), (5, 12), (5, 13), (5, 14), (5, 15), (5, 16), (5, 17), (5, 18), (5, 19), (6, 19), (7, 19), (8, 19), (9, 19), (10, 19), (11, 19), (12, 19), (13, 19), (13, 18), (13, 17), (14, 17), (15, 17), (15, 18), (15, 19), (16, 19), (17, 19), (18, 19), (19, 19)]\n"
          ]
        }
      ],
      "source": [
        "# Testing the agent after training\n",
        "# agent = QLearningAgent(maze)\n",
        "agent.load_model('q_table1.pkl')\n",
        "mypath=test_agent(agent, maze, num_episodes=100)\n",
        "# mypath.remove((0,1))\n",
        "print(mypath)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['moveForward', 'turnRight', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'turnLeft', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'turnRight', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'turnLeft', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'moveForward', 'turnLeft', 'moveForward', 'moveForward', 'turnRight', 'moveForward', 'moveForward', 'turnRight', 'moveForward', 'moveForward', 'turnLeft', 'moveForward', 'moveForward', 'moveForward', 'moveForward']\n"
          ]
        }
      ],
      "source": [
        "def generate_movement_instructions(path):\n",
        "\n",
        "    instructions = []\n",
        "\n",
        "    for i in range(len(path) - 1):\n",
        "        start_x, start_y = path[i]\n",
        "        end_x, end_y = path[i + 1]\n",
        "\n",
        "        # Determine the direction and distance for this segment\n",
        "        if start_x < end_x and start_y == end_y:  # Move forward\n",
        "            direction = \"forward\"\n",
        "            distance = end_x - start_x\n",
        "        elif start_x == end_x and start_y < end_y:  # Turn right\n",
        "            direction = \"right\"\n",
        "            distance = end_y - start_y\n",
        "        elif start_x == end_x and start_y > end_y:  # Turn left\n",
        "            direction = \"left\"\n",
        "            distance = start_y - end_y\n",
        "        else:\n",
        "            direction = \"right\"\n",
        "            distance = start_x - end_x\n",
        "\n",
        "        # Move in the determined direction\n",
        "        while distance > 0:\n",
        "            instructions.append((\"moveForward\"))\n",
        "            distance -= 1\n",
        "\n",
        "        # Turn if necessary for the next segment\n",
        "        if i < len(path) - 2:\n",
        "            next_x, next_y = path[i + 2]\n",
        "            if direction == \"forward\" and next_y != end_y:\n",
        "                instructions.append((\"turnRight\" if next_y > end_y else \"turnLeft\"))\n",
        "            elif direction == \"right\" and next_x != end_x:\n",
        "                instructions.append((\"turnLeft\"))\n",
        "            elif direction == \"left\" and next_x != end_x:\n",
        "                instructions.append((\"turnRight\"))\n",
        "\n",
        "    return instructions\n",
        "\n",
        "instructions = generate_movement_instructions(mypath)\n",
        "with open('Path.txt','w') as file:\n",
        "    file.write(\"\\n\".join(instructions))\n",
        "print(instructions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sending: moveForward\n",
            "Sending: turnRight\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: turnLeft\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: turnRight\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: turnLeft\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: turnLeft\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: turnRight\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: turnRight\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: turnLeft\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Sending: moveForward\n",
            "Error: 'NoneType' object has no attribute 'sock'\n",
            "WebSocket closed: None\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import websocket\n",
        "import time\n",
        "\n",
        "def on_message(ws, message):\n",
        "    print(\"Received from ESP32: \" + message)\n",
        "\n",
        "def on_open(ws):\n",
        "    # Open file in read mode\n",
        "    with open('Path.txt', 'r') as file:\n",
        "        # Iterate through each line in the file\n",
        "        for line in file:\n",
        "            # Send each line over the WebSocket connection\n",
        "            print(f\"Sending: {line.strip()}\")\n",
        "            ws.send(line.strip())  # Send the line to the ESP32\n",
        "\n",
        "            # Optionally wait for a response from ESP32 before sending the next line\n",
        "            time.sleep(1)  # Adjust sleep time as per your requirement\n",
        "\n",
        "    # Close the WebSocket connection after sending all lines\n",
        "    ws.close()\n",
        "\n",
        "def on_error(ws, error):\n",
        "    print(f\"Error: {error}\")\n",
        "\n",
        "def on_close(ws, close_status_code, close_msg):\n",
        "    print(f\"WebSocket closed: {close_msg}\")\n",
        "\n",
        "# WebSocket client setup\n",
        "ws = websocket.WebSocketApp(\n",
        "    \"ws://192.168.13.28:81\",  # Replace with your ESP32 IP address\n",
        "    on_message=on_message,\n",
        "    on_error=on_error,\n",
        "    on_close=on_close\n",
        ")\n",
        "\n",
        "# When the connection is opened, it will start sending data\n",
        "ws.on_open = on_open\n",
        "\n",
        "# Start the WebSocket client and keep it running\n",
        "ws.run_forever()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
